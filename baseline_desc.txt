As our baseline we used Logistic Regression and Majority Class Prediction. We tried both methods and ended up uploading predictions from Logistic Regression since it performed better. The system for Logistic Regression  was designed as a short pipeline, where the feature sentences are transformed using CountVectorizer() from sklearn to a binary bag of words. The best set of hyperparameters (different number of iterations and different strenghts of regularization) was found using GridSearch() from sklearn. The best model achieved cross validated (5 folds) F1 score: 0.94. 
